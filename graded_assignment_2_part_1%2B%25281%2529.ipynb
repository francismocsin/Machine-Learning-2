{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Lab Assignment 2: Evaluate classifiers (10 points)\n",
    " \n",
    "In this assignment you will optimize and compare the perfomance of a parametric (logistic regression) and non-parametric (k-nearest neighbours) classifier on the MNIST dataset.\n",
    "\n",
    "Publish your notebook (ipynb file) to your Machine Learning repository on Github ON TIME. We will check the last commit on the day of the deadline.  \n",
    "\n",
    "### Deadline Friday, November 17, 23:59.\n",
    "\n",
    "This notebook consists of three parts: design, implementation, results & analysis. \n",
    "We provide you with the design of the experiment and you have to implement it and analyse the results.\n",
    "\n",
    "### Criteria used for grading\n",
    "* Explain and analyse all results.\n",
    "* Make your notebook easy to read. When you are finished take your time to review it!\n",
    "* You do not want to repeat the same chunks of code multiply times. If your need to do so, write a function. \n",
    "* The implementation part of this assignment needs careful design before you start coding. You could start by writing pseudocode.\n",
    "* In this exercise the insights are important. Do not hide them somewhere in the comments in the implementation, but put them in the Analysis part\n",
    "* Take care that all the figures and tables are well labeled and numbered so that you can easily refer to them.\n",
    "* A plot should have a title and axes labels.\n",
    "* You may find that not everything is 100% specified in this assignment. That is correct! Like in real life you probably have to make some choices. Motivate your choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading points distribution\n",
    "\n",
    "* Implementation 5 points\n",
    "* Results and analysis 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to keep the order of this design and are allowed to alter it if you are confident.\n",
    "* Import all necessary modules. Try to use as much of the available functions as possible. \n",
    "* Use the provided train and test set of MNIST dataset.\n",
    "* Pre-process data eg. normalize/standardize, reformat, etc.           \n",
    "  Do whatever you think is necessary and motivate your choices.\n",
    "* (1) Train logistic regression and k-nn using default settings.\n",
    "* Use 10-fold cross validation for each classifier to optimize the performance for one parameter: \n",
    "    * consult the documentation on how cross validation works in sklearn (important functions:             cross_val_score(), GridSearchCV()).\n",
    "    * Optimize k for k-nn,\n",
    "    * for logistic regression focus on the regularization parameter,\n",
    "* (2) Train logistic regression and k-nn using optimized parameters.\n",
    "* Show performance on the cross-validation set for (1) and (2) for both classifiers: \n",
    "    * report the average cross validation error rates (alternatively, the average accuracies - it's up to you) and standard deviation,\n",
    "    * plot the average cross valildation errors (or accuracies) for different values of the parameter that you tuned. \n",
    "* Compare performance on the test set for two classifiers:\n",
    "    * produce the classification report for both classifiers, consisting of precision, recall, f1-score. Explain and analyse the results.\n",
    "    * print confusion matrix for both classifiers and compare whether they missclassify the same  classes. Explain and analyse the results.\n",
    "* Discuss your results.\n",
    "* BONUS: only continue with this part if you are confident that your implemention is complete \n",
    "    * tune more parameters of logistic regression\n",
    "    * add additional classifiers (NN, Naive Bayes, decision tree), \n",
    "    * analyse additional dataset (ex. Iris dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on CV set:\n",
      "LogisticRegression:  {'C': 0.1}\n",
      "K-NN:  {'n_neighbors': 3}\n",
      "\n",
      "0.933 (+/-0.037) for {'C': 0.01}\n",
      "0.939 (+/-0.023) for {'C': 0.1}\n",
      "0.935 (+/-0.026) for {'C': 0.3}\n",
      "0.933 (+/-0.030) for {'C': 0.6}\n",
      "0.933 (+/-0.033) for {'C': 1.0}\n",
      "0.929 (+/-0.039) for {'C': 3.0}\n",
      "0.928 (+/-0.041) for {'C': 5.0}\n",
      "0.957 (+/-0.029) for {'n_neighbors': 2}\n",
      "0.959 (+/-0.024) for {'n_neighbors': 3}\n",
      "0.951 (+/-0.027) for {'n_neighbors': 4}\n",
      "0.946 (+/-0.036) for {'n_neighbors': 5}\n",
      "0.941 (+/-0.038) for {'n_neighbors': 6}\n",
      "0.939 (+/-0.039) for {'n_neighbors': 7}\n",
      "\n",
      "A Detailed classification report for Logistic Regression on the Test set:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        27\n",
      "          1       0.79      0.84      0.81        31\n",
      "          2       1.00      1.00      1.00        27\n",
      "          3       0.86      0.63      0.73        30\n",
      "          4       0.97      0.91      0.94        33\n",
      "          5       0.91      0.97      0.94        30\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       0.90      0.90      0.90        30\n",
      "          8       0.68      0.93      0.79        28\n",
      "          9       0.89      0.81      0.85        31\n",
      "\n",
      "avg / total       0.90      0.89      0.89       297\n",
      "\n",
      "\n",
      "A Detailed classification report for K-NN on the Test set:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       0.94      1.00      0.97        31\n",
      "          2       0.96      1.00      0.98        27\n",
      "          3       0.96      0.87      0.91        30\n",
      "          4       1.00      0.91      0.95        33\n",
      "          5       0.91      1.00      0.95        30\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       0.94      1.00      0.97        30\n",
      "          8       0.93      0.93      0.93        28\n",
      "          9       0.97      0.90      0.93        31\n",
      "\n",
      "avg / total       0.96      0.96      0.96       297\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on CV set:\n",
      "LogisticRegression:  {'C': 0.1}\n",
      "K-NN:  {'n_neighbors': 3}\n",
      "\n",
      "0.929 (+/-0.039) for {'C': 0.01}\n",
      "0.935 (+/-0.026) for {'C': 0.1}\n",
      "0.931 (+/-0.029) for {'C': 0.3}\n",
      "0.929 (+/-0.034) for {'C': 0.6}\n",
      "0.929 (+/-0.038) for {'C': 1.0}\n",
      "0.925 (+/-0.043) for {'C': 3.0}\n",
      "0.924 (+/-0.044) for {'C': 5.0}\n",
      "0.954 (+/-0.029) for {'n_neighbors': 2}\n",
      "0.958 (+/-0.024) for {'n_neighbors': 3}\n",
      "0.948 (+/-0.029) for {'n_neighbors': 4}\n",
      "0.943 (+/-0.038) for {'n_neighbors': 5}\n",
      "0.938 (+/-0.041) for {'n_neighbors': 6}\n",
      "0.936 (+/-0.041) for {'n_neighbors': 7}\n",
      "\n",
      "A Detailed classification report for Logistic Regression on the Test set:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98        27\n",
      "          1       0.79      0.84      0.81        31\n",
      "          2       1.00      1.00      1.00        27\n",
      "          3       0.86      0.63      0.73        30\n",
      "          4       0.97      0.91      0.94        33\n",
      "          5       0.91      0.97      0.94        30\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       0.90      0.90      0.90        30\n",
      "          8       0.68      0.93      0.79        28\n",
      "          9       0.89      0.81      0.85        31\n",
      "\n",
      "avg / total       0.90      0.89      0.89       297\n",
      "\n",
      "\n",
      "A Detailed classification report for K-NN on the Test set:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       0.94      1.00      0.97        31\n",
      "          2       0.96      1.00      0.98        27\n",
      "          3       0.96      0.87      0.91        30\n",
      "          4       1.00      0.91      0.95        33\n",
      "          5       0.91      1.00      0.95        30\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       0.94      1.00      0.97        30\n",
      "          8       0.93      0.93      0.93        28\n",
      "          9       0.97      0.90      0.93        31\n",
      "\n",
      "avg / total       0.96      0.96      0.96       297\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (7,) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-57abb104de6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mscores_knnreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknnreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_mnist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_mnist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuned_parameters_logreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_logreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\franc\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3317\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\franc\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1890\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1891\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\franc\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\franc\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\franc\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\franc\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (7,) and (3,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xadb8f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# load mnist dataset and split in train and test set.\n",
    "digits = load_digits()\n",
    "\n",
    "X_train_mnist = reshape(digits.images[:1500],(1500,64))\n",
    "X_test_mnist = reshape(digits.images[1500:],(297,64))\n",
    "y_train_mnist = digits.target[:1500]\n",
    "y_test_mnist = digits.target[1500:]\n",
    "\n",
    "\n",
    "#pre-processing data, it is necessary to normalize data to prevent bad behaviour of estimators\n",
    "#due to individual features not adhering to a Gaussian distribution\n",
    "\n",
    "stats.normaltest(X_train_mnist) #Use the normaltest() function to check if the data has a Normal distribution\n",
    "                                #It turns out the data doesn't have a Normal dist. so we normalize the data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train_mnist)\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters_logreg = [{'C':[0.01, 0.1, 0.3, 0.6, 1.0, 3.0, 5.0 ]}]\n",
    "tuned_parameters_knnreg = [{'n_neighbors': [2, 3, 4, 5, 6, 7]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print()\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    print(\"Best parameters set found on CV set:\")\n",
    "    print(\"LogisticRegression: \", logreg.best_params_)\n",
    "    print(\"K-NN: \", knnreg.best_params_)\n",
    "    print()\n",
    "    \n",
    "    #Loading and Training Logistic Regression and K-NN\n",
    "    \n",
    "    \n",
    "    logreg = GridSearchCV(LogisticRegression(), tuned_parameters_logreg, cv=3, refit=True, scoring='%s_macro' % score)\n",
    "    #Loading in\n",
    "    logreg.fit(X_train_mnist, y_train_mnist) \n",
    "    #Training\n",
    "    \n",
    "    knnreg = GridSearchCV(KNeighborsClassifier(), tuned_parameters_knnreg, cv=3, refit=True,scoring='%s_macro' % score)\n",
    "    knnreg.fit(X_train_mnist, y_train_mnist)\n",
    "    \n",
    "    means_logreg = logreg.cv_results_['mean_test_score'] #Array of average validation scores on the CV sets\n",
    "    stds_logreg = logreg.cv_results_['std_test_score'] #Array of Standard Deviations of the scores on the CV sets\n",
    "    \n",
    "    means_knnreg = knnreg.cv_results_['mean_test_score']\n",
    "    stds_knnreg = knnreg.cv_results_['std_test_score']\n",
    "    \n",
    "    for mean, std, params in zip(means_logreg, stds_logreg, logreg.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "    for mean, std, params in zip(means_knnreg, stds_knnreg, knnreg.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "    print()\n",
    "    print(\"A Detailed classification report for Logistic Regression on the Test set:\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_mnist, logreg.predict(X_test_mnist) #Creates a classification report for LogReg then for K-NN\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"A Detailed classification report for K-NN on the Test set:\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_mnist, knnreg.predict(X_test_mnist)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "#Predictions computed by LogisticRegression and K-NN for CV set\n",
    "scores_logreg = cross_val_score(logreg, X_test_mnist, y_test_mnist, cv=3)\n",
    "scores_knnreg = cross_val_score(knnreg, X_test_mnist, y_test_mnist, cv=3)\n",
    "\n",
    "plt.plot(tuned_parameters_logreg[0][\"C\"], scores_logreg)\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "# your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and analysis of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discuss the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.955992  ,  0.91786315,  0.97371098])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_knnreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91269841,  0.92      ,  0.95564516])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.01535495,  0.01836459,  0.01852687,  0.01519052,  0.0150218 ,\n",
       "         0.01485499]),\n",
       " 'mean_score_time': array([ 0.34069022,  0.43799861,  0.32900651,  0.32565665,  0.31813407,\n",
       "         0.31446195]),\n",
       " 'mean_test_score': array([ 0.95466667,  0.958     ,  0.94866667,  0.94333333,  0.938     ,\n",
       "         0.936     ]),\n",
       " 'mean_train_score': array([ 0.99233325,  0.99399726,  0.99233325,  0.99066657,  0.9903319 ,\n",
       "         0.99033589]),\n",
       " 'param_n_neighbors': masked_array(data = [2 3 4 5 6 7],\n",
       "              mask = [False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7}),\n",
       " 'rank_test_score': array([2, 1, 3, 4, 5, 6], dtype=int32),\n",
       " 'split0_test_score': array([ 0.95238095,  0.95634921,  0.94642857,  0.9484127 ,  0.94047619,\n",
       "         0.93452381]),\n",
       " 'split0_train_score': array([ 0.99196787,  0.99196787,  0.99196787,  0.99096386,  0.98995984,\n",
       "         0.99096386]),\n",
       " 'split1_test_score': array([ 0.938,  0.944,  0.932,  0.918,  0.912,  0.912]),\n",
       " 'split1_train_score': array([ 0.993,  0.996,  0.993,  0.99 ,  0.99 ,  0.991]),\n",
       " 'split2_test_score': array([ 0.97379032,  0.97379032,  0.96774194,  0.96370968,  0.96169355,\n",
       "         0.96169355]),\n",
       " 'split2_train_score': array([ 0.99203187,  0.9940239 ,  0.99203187,  0.99103586,  0.99103586,\n",
       "         0.98904382]),\n",
       " 'std_fit_time': array([ 0.00062633,  0.0037166 ,  0.00414944,  0.00023507,  0.0004091 ,\n",
       "         0.00023591]),\n",
       " 'std_score_time': array([ 0.01371636,  0.03055145,  0.01739688,  0.00876467,  0.02643498,\n",
       "         0.0162265 ]),\n",
       " 'std_test_score': array([ 0.01467234,  0.01219408,  0.01464903,  0.01897066,  0.02032301,\n",
       "         0.02027374]),\n",
       " 'std_train_score': array([ 0.00047219,  0.00164622,  0.00047219,  0.00047225,  0.00049804,\n",
       "         0.00091375])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnreg.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89898989898989901"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_knnreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.1, 0.3, 0.6, 1.0, 3.0, 5.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters_logreg[0][\"C\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
